{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "604923dc",
   "metadata": {},
   "source": [
    "# CSPB 3202 - Final Project \n",
    "\n",
    "## Reinforcement Learning - Lunar Lander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28cbd0",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "1. Overview\n",
    "2. Approach\n",
    "3. Results\n",
    "4. Conclusion\n",
    "5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74f2265",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "In this project I'm going to be creating an agent to control the Lunar Lander Box2D environment from Gymnasium. The Lunar Lander environment can be referenced here: \n",
    "\n",
    "https://gymnasium.farama.org/environments/box2d/lunar_lander/\n",
    "\n",
    "To begin I will implement a random agent to control the Lunar Lander. Then I will implement a heruistic agent. Finally I will implement a reinforcement learning model. \n",
    "\n",
    "#### Lunar Lander Environment Description\n",
    "\n",
    "**Objective**\n",
    "\n",
    "The objective of the Lunar Landar Environment is to land between the flags. \n",
    "\n",
    "**Action Space**\n",
    "\n",
    "There are 4 actions that can be taken:\n",
    "\n",
    "* 0: Do Nothing\n",
    "* 1: Fire Left Engine\n",
    "* 2: Fire Main Engine\n",
    "* 3: Fire Right Engine\n",
    "\n",
    "**Obervables**\n",
    "\n",
    "Example obervable:\n",
    "\n",
    "```Box([ -2.5 -2.5 -10. -10. -6.2831855 -10. -0. -0. ], [ 2.5 2.5 10. 10. 6.2831855 10. 1. 1. ], (8,), float32)```\n",
    "\n",
    "\n",
    "|Definition|Value|\n",
    "|:---------|:----|\n",
    "|x coordinate|-2.5|\n",
    "|y coordinate|-2.5|\n",
    "|x linear velocity|-10|\n",
    "|y linear velocity|-10|\n",
    "|angle|-6.2831855|\n",
    "|angular velocity|-10|\n",
    "|leg one touchdown|0|\n",
    "|leg two touchdown|0|\n",
    "\n",
    "**Reward Criteria**\n",
    "\n",
    "Each step the following items impact the reward.\n",
    "\n",
    "- Distance from landing pad\n",
    "- Movement speed\n",
    "- Lander tilt\n",
    "- Contact of each leg\n",
    "- Number of times the engines are fired\n",
    "- Landing safely\n",
    "\n",
    "The total reward is the sum of all the rewards for all steps in the episode. OpenAI states that an episode is considered a solution of it scores at least 200 points. \n",
    "\n",
    "**Termination Criteria**\n",
    "\n",
    "The episode is terminated if the lander crashes, it gets outside the viewpoint, or it's not active.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34474c5c-d2bf-466b-a785-2e25d9a239af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n",
      "/home/rei/anaconda3/envs/ai_env/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Initialise the environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "    # this is where you would insert your policy\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # step (transition) through the environment with the action\n",
    "    # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052cc27-6aab-410b-88d3-9743a636ac36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
